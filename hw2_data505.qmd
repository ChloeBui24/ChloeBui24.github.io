---
title: "hw2_data505"
author: "Chloe Bui"
date: 1/31/2025
format: html
---

## Prepare the data

```{r}
library(tidyverse)
library(caret)
library(fastDummies)
wine <- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/wine.rds")))
```

**Explanation:**

> *1.loads the tidyverse package*
>
> *2.load the caret package*
>
> *3.load the fastDummies package*
>
> *4.reads a compressed RDS file directly from a URL*

## Feature Engineering

We begin by engineering an number of features.

1.  Create a total of 10 features (including points).
2.  Remove all rows with a missing value.
3.  Ensure only log(price) and engineering features are the only columns that remain in the `wino` dataframe.

```{r}
wino = wine %>% 
  mutate(lprice=log(price)) %>%                    # feature 1
  mutate(country = fct_lump(country, 3)) %>%       # feature 2:4
  mutate(variety = fct_lump(variety, 3)) %>%       # feature 5:7
  mutate(winery = fct_lump(winery, 3)) %>%         # feature 8:10
  select(lprice, points, country, variety, winery) %>%
  drop_na(.)

head(wino)
```

**Explanation:**

> *1. create a new feature as the logarithm of price column*
>
> *2. collapse the country/variety/winery factor into the top 3 most frequent levels and combines all others into an "Other" category*
>
> *3. select only 4 columns: lprice, points, country, variety, winery*
>
> *4. remove rows with missing value*

```{r}
renamer <- function(s) {
  s %>% tolower() %>% str_replace("-| ", "_")}

wino <- wino %>%
  dummy_cols(remove_selected_columns = TRUE) %>%
  rename_with(.fn = renamer) %>%
  select(-ends_with("other"))

head(wino)
```

**Explanation:**

> *1. Build function renamer: convert string to lower case and replace "-" or " " by "-"*
>
> *2. Convert categorical variables into dummy columns while removing the original categorical columns.*
>
> *3. Rename all column names by applying the `renamer` function*
>
> *4. Remove columns that end with "other"*

## Caret

We now use a train/test split to evaluate the features.

1.  Use the Caret library to partition the wino dataframe into an 80/20 split.
2.  Run a linear regression with bootstrap resampling.
3.  Report RMSE on the test partition of the data.

```{r}
# Partition
wine_index <- createDataPartition(wino$lprice, p = 0.8, list = FALSE)
wino_tr <- wino[wine_index, ]
wino_te <- wino[-wine_index, ]
```

**Explanation:**

> *Randomly split the data to 2 data sets: 80% data for training and 20% for testing*

```{r}
# linear regression with bootstrap resampling
do_training2 <- function(df, formula) {
  train(
    formula,
    data = df,
    method = "lm",
    trControl = trainControl(method = "boot", number = 10))}

mod <- do_training2(
  wino_tr, lprice ~ .)

mod

```

**Explanation:**

> *1. Build function do_training2 using bootstrap resampling with 10 bootstrap iterations*
>
> *2. Fit the model to the training data set*

```{r}
# Report RMSE on the test partition of the data
postResample(
  pred = predict(mod, wino_te),
  obs = wino_te$lprice)

```

**Explanation:**

> *Predict the log(price) of testing data set based on the trained model "mod"*

**Interpretation:**

> 1.  *RMSE = 0.49, meaning on average, the model's predictions deviate from the actual values by around 0.49 units in log(price).*
> 2.  *Rsquared = 0.4444549, meaning 44.44 % of the variation in log(price) is explained by the predictors in the model.*
> 3.  *MAE = 0.38, meaning on average, the model's prediction deviate from the true log(price) value by 0.38 units.*

## Variable Selection

We now graph the importance of your 10 features

```{r}
plot(varImp(mod, scale = TRUE))
```
